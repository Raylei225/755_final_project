{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06a69588",
   "metadata": {},
   "source": [
    "## Deep Learning Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b6a8798-e7b2-48a6-a319-2e514c2d3d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "Keras version: 3.10.0\n",
      "Import successful!\n"
     ]
    }
   ],
   "source": [
    "#Run the following to check which is not working in case importing tensorflow and keras failed\n",
    "\n",
    "# import tensorflow as tf\n",
    "# print(f\"TensorFlow version: {tf.__version__}\")\n",
    "# print(f\"Keras version: {tf.keras.__version__}\")\n",
    "\n",
    "# # Test the specific import that was failing\n",
    "# from tensorflow.keras.datasets import mnist\n",
    "# print(\"Import successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b3b014e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import successful\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "print(\"import successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55ac9be-ef38-4856-8b0c-98a579121346",
   "metadata": {},
   "source": [
    "## Dataset + Default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "037dbe1b-e305-4d59-bfdb-cc73cd65328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a99e4566-f723-4aa5-8014-7e6090c9a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"NN_wide_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a543a5e9-f883-49ce-b69b-693f3534ea1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>state</th>\n",
       "      <th>total_diff</th>\n",
       "      <th>gtrend_diff</th>\n",
       "      <th>pop_diff</th>\n",
       "      <th>pov_diff</th>\n",
       "      <th>income_diff</th>\n",
       "      <th>unemployed_diff</th>\n",
       "      <th>urban_pop_percent</th>\n",
       "      <th>rural_pop_percent</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>-1707</td>\n",
       "      <td>-26.865672</td>\n",
       "      <td>286087</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>7970</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>59.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>-125</td>\n",
       "      <td>-44.776119</td>\n",
       "      <td>-1116</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20350</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>66.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>15285</td>\n",
       "      <td>-26.865672</td>\n",
       "      <td>838337</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>18230</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>89.8</td>\n",
       "      <td>10.2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1012</td>\n",
       "      <td>-23.880597</td>\n",
       "      <td>109004</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>12420</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>56.2</td>\n",
       "      <td>43.8</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>California</td>\n",
       "      <td>14558</td>\n",
       "      <td>-18.292683</td>\n",
       "      <td>944925</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>16630</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>95.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       state  total_diff  gtrend_diff  pop_diff  pov_diff  \\\n",
       "0           1     Alabama       -1707   -26.865672    286087      -3.2   \n",
       "1           2      Alaska        -125   -44.776119     -1116       0.4   \n",
       "2           3     Arizona       15285   -26.865672    838337      -6.0   \n",
       "3           4    Arkansas        1012   -23.880597    109004      -4.0   \n",
       "4           5  California       14558   -18.292683    944925      -4.8   \n",
       "\n",
       "   income_diff  unemployed_diff  urban_pop_percent  rural_pop_percent  \\\n",
       "0         7970             -4.7               59.0               41.0   \n",
       "1        20350             -2.5               66.0               34.0   \n",
       "2        18230             -3.9               89.8               10.2   \n",
       "3        12420             -3.6               56.2               43.8   \n",
       "4        16630             -3.9               95.0                5.0   \n",
       "\n",
       "      label  \n",
       "0  negative  \n",
       "1  negative  \n",
       "2  positive  \n",
       "3  positive  \n",
       "4  positive  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "40e2805d-5f7d-4e70-940e-4fcfe35c1122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 11)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "de3de0b4-cb72-48b5-a8ba-c69b04c892dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove 'label' column and 'state' column as current pipeline is not yet compitible with non-numeric valeus\n",
    "\n",
    "df.drop(\"label\", axis = 1, inplace=True)\n",
    "df.drop('state', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "04d5695b-fa0c-4216-9b70-70d713d6a164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 9)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "25df9007-d8bb-431f-a0c1-4a5e4ca84c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('total_diff', axis=1)\n",
    "y = df['total_diff']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size = 0.2,\n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7879a421-f9d3-443d-b257-dc37c43b203e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution:\n",
      "label\n",
      "positive    0.8\n",
      "negative    0.2\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test set class distribution:\n",
      "label\n",
      "positive    0.818182\n",
      "negative    0.181818\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Check class distribution between train and test sets\n",
    "\n",
    "print(\"Training set class distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"\\nTest set class distribution:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b3911c-c72e-4d14-86f2-daddb8987731",
   "metadata": {},
   "source": [
    "### Transfer train and test sets into np array so that it has the format of (features, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "963a338c-fa2f-499e-bc07-95e22f2ccd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_array = X_train.values.T\n",
    "y_train_array = y_train.values.T\n",
    "X_test_array = X_test.values.T\n",
    "y_test_array = y_test.values.T\n",
    "\n",
    "y_train_array = y_train_array.reshape(1, X_train_array.shape[1])\n",
    "y_test_array = y_test_array.reshape(1, X_test_array.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "80e71091-4b99-4c14-97c7-027b23e9bbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 40)\n",
      "(1, 40)\n",
      "(8, 11)\n",
      "(1, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_array.shape)\n",
    "print(y_train_array.shape)\n",
    "print(X_test_array.shape)\n",
    "print(y_test_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eee049-672e-4f4e-85e5-bae5c617b6e3",
   "metadata": {},
   "source": [
    "### Normalize the features in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0c3b0dd2-ef36-4247-b34f-dbed796d61de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = (X_train_array - np.mean(X_train_array, axis=1, keepdims=True)) / (np.std(X_train_array, axis=1, keepdims=True) + 1e-8)\n",
    "X_test_norm = (X_test_array - np.mean(X_test_array, axis=1, keepdims=True)) / (np.std(X_test_array, axis=1, keepdims=True) + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b060e177-9e4c-4266-82b2-9131490d8581",
   "metadata": {},
   "source": [
    "### Define activation functions\n",
    "\n",
    "`sigmoid_stable` and `softmax_stable` are defined and applied to replace original `sigmoid` and `softmax` function as they could cause overflow issues due to data characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c7c80704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activation Functions\n",
    "\n",
    "def sigmoid(Z):\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    return A\n",
    "\n",
    "def softmax(z):\n",
    "    expZ = np.exp(z)\n",
    "    return expZ/(np.sum(expZ, 0))\n",
    "\n",
    "def relu(Z):\n",
    "    A = np.maximum(0,Z)\n",
    "    return A\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def derivative_relu(Z):\n",
    "    return np.array(Z > 0, dtype = 'float')\n",
    "\n",
    "def derivative_tanh(x):\n",
    "    return (1 - np.power(x, 2))\n",
    "\n",
    "def sigmoid_stable(Z):\n",
    "    \"\"\"Numerically stable sigmoid that never outputs exactly 0 or 1\"\"\"\n",
    "    Z = np.clip(Z, -500, 500)  # Prevent overflow\n",
    "    sigmoid_output = 1 / (1 + np.exp(-Z))\n",
    "    \n",
    "    # Ensure output is never exactly 0 or 1\n",
    "    sigmoid_output = np.clip(sigmoid_output, 1e-15, 1 - 1e-15)\n",
    "    return sigmoid_output\n",
    "\n",
    "def softmax_stable(Z):\n",
    "    \"\"\"Numerically stable softmax activation\"\"\"\n",
    "    Z_shifted = Z - np.max(Z, axis=0, keepdims=True)  # Subtract max for stability\n",
    "    exp_Z = np.exp(Z_shifted)\n",
    "    return exp_Z / np.sum(exp_Z, axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0ecc847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Parameters\n",
    "\n",
    "def initialize_parameters(layer_dims):\n",
    "    \n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            \n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) / np.sqrt(layer_dims[l-1]) #*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ea3c20ad-3ae4-4dec-98fd-ee499c004c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of W1: (100, 8)\n",
      "Shape of B1: (100, 1) \n",
      "\n",
      "Shape of W2: (200, 100)\n",
      "Shape of B2: (200, 1) \n",
      "\n",
      "Shape of W3: (1, 200)\n",
      "Shape of B3: (1, 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check for initialization\n",
    "\n",
    "layer_dims = [X_train_norm.shape[0], 100, 200, y_train_array.shape[0]]\n",
    "params = initialize_parameters(layer_dims)\n",
    "\n",
    "for l in range(1, len(layer_dims)):\n",
    "    print(\"Shape of W\" + str(l) + \":\", params['W' + str(l)].shape)\n",
    "    print(\"Shape of B\" + str(l) + \":\", params['b' + str(l)].shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85d9ec9-b3fd-42c0-b507-2ccd7692b00c",
   "metadata": {},
   "source": [
    "## Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "891ce5a9-d422-42a0-8ffc-24fd4f39b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters, activation):\n",
    "   \n",
    "    forward_cache = {}\n",
    "    L = len(parameters) // 2                  \n",
    "    \n",
    "    forward_cache['A0'] = X\n",
    "\n",
    "    for l in range(1, L):\n",
    "        forward_cache['Z' + str(l)] = parameters['W' + str(l)].dot(forward_cache['A' + str(l-1)]) + parameters['b' + str(l)]\n",
    "        \n",
    "        if activation == 'tanh':\n",
    "            forward_cache['A' + str(l)] = tanh(forward_cache['Z' + str(l)])\n",
    "        else:\n",
    "            forward_cache['A' + str(l)] = relu(forward_cache['Z' + str(l)])\n",
    "            \n",
    "\n",
    "    forward_cache['Z' + str(L)] = parameters['W' + str(L)].dot(forward_cache['A' + str(L-1)]) + parameters['b' + str(L)]\n",
    "    \n",
    "    if forward_cache['Z' + str(L)].shape[0] == 1:\n",
    "        forward_cache['A' + str(L)] = sigmoid_stable(forward_cache['Z' + str(L)])\n",
    "    else :\n",
    "        forward_cache['A' + str(L)] = softmax_stable(forward_cache['Z' + str(L)])\n",
    "    \n",
    "    return forward_cache['A' + str(L)], forward_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "57532f26-492c-4c15-9cbc-0a94ec42b476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of A0 : (8, 40)\n",
      "Shape of A1 : (100, 40)\n",
      "Shape of A2 : (200, 40)\n",
      "Shape of A3 : (1, 40)\n"
     ]
    }
   ],
   "source": [
    "#Check for the forward propagation\n",
    "\n",
    "aL, forw_cache = forward_propagation(X_train_norm, params, 'relu')\n",
    "\n",
    "for l in range(len(params)//2 + 1):\n",
    "    print(\"Shape of A\" + str(l) + \" :\", forw_cache['A' + str(l)].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1184f170-bcc3-499b-86c2-0581a76051ee",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "315966d6-bbbb-4c23-be32-3919a1816f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    if Y.shape[0] == 1:\n",
    "        cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
    "    else:\n",
    "        cost = -(1./m) * np.sum(Y * np.log(AL))\n",
    "        \n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77f66ce-e3ff-42fe-b794-394dd15a2f26",
   "metadata": {},
   "source": [
    "## Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "457c16ec-1978-43ec-8e9a-ab2e7b20cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(AL, Y, parameters, forward_cache, activation):\n",
    "    \n",
    "    grads = {}\n",
    "    L = len(parameters)//2\n",
    "    m = AL.shape[1]\n",
    "    \n",
    "    grads[\"dZ\" + str(L)] = AL - Y\n",
    "    grads[\"dW\" + str(L)] = 1./m * np.dot(grads[\"dZ\" + str(L)],forward_cache['A' + str(L-1)].T)\n",
    "    grads[\"db\" + str(L)] = 1./m * np.sum(grads[\"dZ\" + str(L)], axis = 1, keepdims = True)\n",
    "    \n",
    "    for l in reversed(range(1, L)):\n",
    "        if activation == 'tanh':\n",
    "            grads[\"dZ\" + str(l)] = np.dot(parameters['W' + str(l+1)].T,grads[\"dZ\" + str(l+1)])*derivative_tanh(forward_cache['A' + str(l)])\n",
    "        else:\n",
    "            grads[\"dZ\" + str(l)] = np.dot(parameters['W' + str(l+1)].T,grads[\"dZ\" + str(l+1)])*derivative_relu(forward_cache['A' + str(l)])\n",
    "            \n",
    "        grads[\"dW\" + str(l)] = 1./m * np.dot(grads[\"dZ\" + str(l)],forward_cache['A' + str(l-1)].T)\n",
    "        grads[\"db\" + str(l)] = 1./m * np.sum(grads[\"dZ\" + str(l)], axis = 1, keepdims = True)\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9a4796e1-0276-4876-873e-39509979b526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dZ3 : (1, 40)\n",
      "Shape of dW3 : (1, 200)\n",
      "Shape of dB3 : (1, 1) \n",
      "\n",
      "Shape of dZ2 : (200, 40)\n",
      "Shape of dW2 : (200, 100)\n",
      "Shape of dB2 : (200, 1) \n",
      "\n",
      "Shape of dZ1 : (100, 40)\n",
      "Shape of dW1 : (100, 8)\n",
      "Shape of dB1 : (100, 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check for backward propagation\n",
    "\n",
    "grads = backward_propagation(forw_cache[\"A\" + str(3)], y_train_array, params, forw_cache, 'relu')\n",
    "\n",
    "for l in reversed(range(1, len(grads)//3 + 1)):\n",
    "    print(\"Shape of dZ\" + str(l) + \" :\", grads['dZ' + str(l)].shape)\n",
    "    print(\"Shape of dW\" + str(l) + \" :\", grads['dW' + str(l)].shape)\n",
    "    print(\"Shape of dB\" + str(l) + \" :\", grads['db' + str(l)].shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "697eef33-f168-4901-8abd-60a2a988394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update Parameters\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "\n",
    "    L = len(parameters) // 2 \n",
    "    \n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c526eba-9979-4cdb-98a6-2ce4bff7927d",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b32ed014-7804-46a3-b012-fe451af32573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters, activation):\n",
    "\n",
    "    m = X.shape[1]\n",
    "    y_pred, caches = forward_propagation(X, parameters, activation)\n",
    "    \n",
    "    if y.shape[0] == 1:\n",
    "        y_pred = np.array(y_pred > 0.5, dtype = 'float')\n",
    "    else:\n",
    "        y = np.argmax(y, 0)\n",
    "        y_pred = np.argmax(y_pred, 0)\n",
    "    \n",
    "    return np.round(np.sum((y_pred == y)/m), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943e918d-01e6-4e99-b5ae-5a5f1288c2b4",
   "metadata": {},
   "source": [
    "## Implement Network\n",
    "\n",
    "Initialize parameters once, and then run the following in loop:\n",
    "1. forward_prop(x, parameters)\r",
    "2. cost_function(aL, y)\n",
    "3. \n",
    "backward_prop(x, y, parameters, forward_cach)\n",
    "4. \r\n",
    "parameters = update_parameters(parameters, gradients, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6eb700f4-6315-4eb0-b8db-900bb090a9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, layers_dims, learning_rate = 0.03, activation = 'relu', num_iterations = 3000):#lr was 0.009\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []              \n",
    "    \n",
    "    parameters = initialize_parameters(layers_dims)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        AL, forward_cache = forward_propagation(X, parameters, activation)\n",
    "\n",
    "        cost = compute_cost(AL, Y)\n",
    "\n",
    "        grads = backward_propagation(AL, Y, parameters, forward_cache, activation)\n",
    "\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "        if i % (num_iterations/10) == 0:\n",
    "            print(\"\\niter:{} \\t cost: {} \\t train_acc:{} \\t test_acc:{}\".format(i, np.round(cost, 2), predict(X_train_norm, y_train_array, parameters, activation), predict(X_test_norm, y_test_array, parameters, activation)))\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"==\", end = '')\n",
    "\n",
    "       \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7c18fed4-3ca1-40ed-9edd-73e6eb1fa81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iter:0 \t cost: 181148.97 \t train_acc:0.0 \t test_acc:0.0\n",
      "==================================================\n",
      "iter:250 \t cost: nan \t train_acc:0.0 \t test_acc:0.0\n",
      "==================================================\n",
      "iter:500 \t cost: nan \t train_acc:0.0 \t test_acc:0.0\n",
      "==================================================\n",
      "iter:750 \t cost: nan \t train_acc:0.0 \t test_acc:0.0\n",
      "==================================================\n",
      "iter:1000 \t cost: nan \t train_acc:0.0 \t test_acc:0.0\n",
      "==================================================\n",
      "iter:1250 \t cost: nan \t train_acc:0.0 \t test_acc:0.0\n",
      "==================================================\n",
      "iter:1500 \t cost: nan \t train_acc:0.0 \t test_acc:0.0\n",
      "==================================================\n",
      "iter:1750 \t cost: nan \t train_acc:0.0 \t test_acc:0.0\n",
      "==================================================\n",
      "iter:2000 \t cost: nan \t train_acc:0.0 \t test_acc:0.0\n",
      "==================================================\n",
      "iter:2250 \t cost: nan \t train_acc:0.0 \t test_acc:0.0\n",
      "=================================================="
     ]
    }
   ],
   "source": [
    "layers_dims = [X_train_array.shape[0], 20, 7, 5, y_train_array.shape[0]] #  4-layer model\n",
    "lr = 0.0075\n",
    "iters = 2500\n",
    "\n",
    "parameters = model(X_train_array, y_train_array, layers_dims, learning_rate = lr, activation = 'relu', num_iterations = iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abed0a8-48ed-424b-a9d2-b5a900285b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
